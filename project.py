# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1woDel_hnOFYn9AHw3gt3X5zufUXWqTXJ
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,PolynomialFeatures
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report,mean_squared_error, r2_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LinearRegression,Ridge
from sklearn.ensemble import RandomForestRegressor

df = pd.read_csv('dataset_Facebook.csv', sep=';')
df['Type'] = df['Type'].map({'Photo': 1, 'Status': 2, 'Link': 3,"Video":4})
df_ready = df.dropna()

selected_features_classificationforpaid = [
    "Page total likes", "Post Hour", "Lifetime Post Total Reach", "Lifetime Post Total Impressions",
    "Lifetime Engaged Users", "Lifetime Post Consumers", "Lifetime Post Consumptions",
    "Lifetime Post Impressions by people who have liked your Page",
    "Lifetime Post reach by people who like your Page",
    "Lifetime People who have liked your Page and engaged with your post",
    "comment", "like", "share", "Total Interactions"
]
selected_features_regressionforinteactions = [
    "Lifetime Post Total Reach", "Lifetime Post Total Impressions","Lifetime Post Consumers","Lifetime Engaged Users","Lifetime Post Consumptions",
    "Lifetime Post Impressions by people who have liked your Page",
    "Lifetime Post reach by people who like your Page",
    "Lifetime People who have liked your Page and engaged with your post",
    "Paid"
]

X = df_ready[selected_features_classificationforpaid]
y = df_ready["Paid"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
n_estimators_list = [10, 50, 100, 200]
max_depth_list = [2, 4, 6, 8]
results = {}
best_scoreRandom = 0
best_params = {}
rf_results = []
acc_scores = []
for depth in max_depth_list:
    for n_estimators in n_estimators_list:
        clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=depth, random_state=42)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        acc = accuracy_score(y_test, y_pred)
        acc_scores.append(acc)
        rf_results.append({'N_estimators': n_estimators, 'Max_depth': depth, 'Accuracy': acc})
        if acc > best_scoreRandom:
            best_scoreRandom = acc
            best_params = {'N_estimators': n_estimators, 'Max_depth': depth}
            best_model = clf
    results[depth] = acc_scores
y_pred_best = best_model.predict(X_test)
print(f"Best Parameters: N_estimators = {best_params['N_estimators']}, Max_depth = {best_params['Max_depth']}")
print("Classification Report: \n", classification_report(y_test,y_pred_best))
rf_df = pd.DataFrame(rf_results)

X = df_ready[selected_features_classificationforpaid]
y = df_ready["Paid"]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
k_values = list(range(1, 21))
accuracies = []
knn_results = []
for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    accuracies.append(acc)
    knn_results.append({ 'K': k, 'Accuracy': acc})
best_k = k_values[accuracies.index(max(accuracies))]
knn_final = KNeighborsClassifier(n_neighbors=best_k)
knn_final.fit(X_train, y_train)
y_pred_final = knn_final.predict(X_test)
print("Best k:", best_k)
print("Classification Report: \n", classification_report(y_test,y_pred_final))
bestknn =accuracy_score(y_test, y_pred_final)
knn_df = pd.DataFrame(knn_results)

X = df_ready[selected_features_classificationforpaid]
y = df_ready["Paid"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
model = GaussianNB()
model.fit(X_train, y_train)
predictions = model.predict(X_test)
print("Classification Report: \n", classification_report(y_test,predictions))
Naiveacc = accuracy_score(y_test, predictions)

X = df_ready[selected_features_regressionforinteactions]
y = df_ready["Total Interactions"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
n_estimators_list = [10, 50, 100, 200]
max_depth_list = [2, 4, 6, 8]
results = {}
best_scoreRandomreg = 0
best_params = {}
rfreg_results = []
acc_scores = []
for depth in max_depth_list:
    for n_estimators in n_estimators_list:
        clf = RandomForestRegressor(n_estimators=n_estimators, max_depth=depth, random_state=0)
        clf.fit(X_train, y_train)
        y_pred = clf.predict(X_test)
        acc = r2_score(y_test, y_pred)
        acc_scores.append(acc)
        rfreg_results.append({'N_estimators': n_estimators, 'Max_depth': depth, 'R2_Score': acc})
        if acc > best_scoreRandomreg:
            best_scoreRandomreg = acc
            best_params = {'N_estimators': n_estimators, 'Max_depth': depth}
            best_model = clf
    results[depth] = acc_scores
y_pred_best = best_model.predict(X_test)
print(f"Best Parameters: N_estimators = {best_params['N_estimators']}, Max_depth = {best_params['Max_depth']}")
print("R2 Score: \n", r2_score(y_test, y_pred_best))
print(f"MSE: {mean_squared_error(y_test, y_pred_best)}")
rfreg_df = pd.DataFrame(rfreg_results)

degrees = [1, 2]
poly_results = []
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
for degree in degrees:
    poly_features = PolynomialFeatures(degree)
    x_poly_train = poly_features.fit_transform(X_train_scaled)
    x_poly_test = poly_features.transform(X_test_scaled)
    model = LinearRegression()
    model.fit(x_poly_train, y_train)
    y_pred = model.predict(x_poly_test)
    poly_results.append({'Degree': degree,'MSE': mean_squared_error(y_test, y_pred),'R2': r2_score(y_test, y_pred)})
    acc = r2_score(y_test, y_pred)
    print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))
    print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))
poly_df = pd.DataFrame(poly_results)

alphas = [100, 10, 1, 0.1, 0.001]
ridge_results = []
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
for degree in degrees:
    poly_features = PolynomialFeatures(degree)
    x_poly_train = poly_features.fit_transform(X_train_scaled)
    x_poly_test = poly_features.transform(X_test_scaled)
    for alpha in alphas:
      poly_features = PolynomialFeatures(degree)
      x_poly_train = poly_features.fit_transform(X_train_scaled)
      x_poly_test = poly_features.transform(X_test_scaled)
      model = Ridge(alpha=alpha)
      model.fit(x_poly_train, y_train)
      y_pred = model.predict(x_poly_test)
      ridge_results.append({'Degree': degree ,'Alpha': alpha,'MSE': mean_squared_error(y_test, y_pred),'R2': r2_score(y_test, y_pred)})
      print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))
      print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))
ridge_df = pd.DataFrame(ridge_results)

resultsclass_dict = [
    {"Classifier": "Random Forest", "Score": best_scoreRandom},
    {"Classifier": "KNN", "Score": bestknn},
    {"Classifier": "Naive Bayes", "Score": Naiveacc}
]
resultsclass_df = pd.DataFrame(resultsclass_dict)

ridge_max_r2 = max(ridge_results, key=lambda x: x['R2'])['R2']
poly_max_r2 = max(poly_results, key=lambda x: x['R2'])['R2']
resultsreg_dict = [
    {"Regression": "Ridge", "Score": ridge_max_r2},
    {"Regression": "Polynomial", "Score": poly_max_r2},
    {"Regression": "Random forest", "Score": best_scoreRandomreg}
]
resultsreg_df = pd.DataFrame(resultsreg_dict)